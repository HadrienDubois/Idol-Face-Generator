{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\n!pip uninstall opencv-python -y\n!pip uninstall opencv-contrib-python -y\n!pip uninstall opencv-python-headless -y\n!pip install opencv-python==4.5.4.60\n!pip install opencv-python-headless==4.5.4.60\n!pip install opencv-contrib-python==4.5.4.60\n!pip install imutils\n!pip install dlib\n!pip install tensorflow_addons\n!pip install autocrop \n\nimport numpy as np\nimport pandas as pd\nimport random as rd\nimport cv2\nimport os\nimport math\n\nimport matplotlib.pyplot as plt\n\nfrom enum import Enum\nfrom glob import glob\nfrom functools import partial\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow_addons.layers import InstanceNormalization\n\nimport sys\nfrom pathlib import Path\nimport PIL\nfrom autocrop import Cropper\n\nimport imutils\nimport dlib\n#from imutils.face_utils import FaceAligner\nfrom imutils.face_utils import rect_to_bb\nfrom imutils.face_utils import FACIAL_LANDMARKS_IDXS","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from imutils.face_utils.helpers import FACIAL_LANDMARKS_68_IDXS\nfrom imutils.face_utils.helpers import FACIAL_LANDMARKS_5_IDXS\nfrom imutils.face_utils.helpers import shape_to_np\nimport numpy as np\nimport cv2\n\nclass FaceAligner:\n\tdef __init__(self, predictor, desiredLeftEye=(0.35, 0.35),\n\t\tdesiredFaceWidth=512, desiredFaceHeight=None):\n\t\t# store the facial landmark predictor, desired output left\n\t\t# eye position, and desired output face width + height\n\t\tself.predictor = predictor\n\t\tself.desiredLeftEye = desiredLeftEye\n\t\tself.desiredFaceWidth = desiredFaceWidth\n\t\tself.desiredFaceHeight = desiredFaceHeight\n\n\t\t# if the desired face height is None, set it to be the\n\t\t# desired face width (normal behavior)\n\t\tif self.desiredFaceHeight is None:\n\t\t\tself.desiredFaceHeight = self.desiredFaceWidth\n\n\tdef align(self, image, gray, rect):\n\t\t# convert the landmark (x, y)-coordinates to a NumPy array\n\t\tshape = self.predictor(gray, rect)\n\t\tshape = shape_to_np(shape)\n\t\t\n\t\t#simple hack ;)\n\t\tif (len(shape)==68):\n\t\t\t# extract the left and right eye (x, y)-coordinates\n\t\t\t(lStart, lEnd) = FACIAL_LANDMARKS_68_IDXS[\"left_eye\"]\n\t\t\t(rStart, rEnd) = FACIAL_LANDMARKS_68_IDXS[\"right_eye\"]\n\t\telse:\n\t\t\t(lStart, lEnd) = FACIAL_LANDMARKS_5_IDXS[\"left_eye\"]\n\t\t\t(rStart, rEnd) = FACIAL_LANDMARKS_5_IDXS[\"right_eye\"]\n\t\t\t\n\t\tleftEyePts = shape[lStart:lEnd]\n\t\trightEyePts = shape[rStart:rEnd]\n\n\t\t# compute the center of mass for each eye\n\t\tleftEyeCenter = leftEyePts.mean(axis=0).astype(\"int\")\n\t\trightEyeCenter = rightEyePts.mean(axis=0).astype(\"int\")\n\n\t\t# compute the angle between the eye centroids\n\t\tdY = rightEyeCenter[1] - leftEyeCenter[1]\n\t\tdX = rightEyeCenter[0] - leftEyeCenter[0]\n\t\tangle = np.degrees(np.arctan2(dY, dX)) - 180\n\n\t\t# compute the desired right eye x-coordinate based on the\n\t\t# desired x-coordinate of the left eye\n\t\tdesiredRightEyeX = 1.0 - self.desiredLeftEye[0]\n\n\t\t# determine the scale of the new resulting image by taking\n\t\t# the ratio of the distance between eyes in the *current*\n\t\t# image to the ratio of distance between eyes in the\n\t\t# *desired* image\n\t\tdist = np.sqrt((dX ** 2) + (dY ** 2))\n\t\tdesiredDist = (desiredRightEyeX - self.desiredLeftEye[0])\n\t\tdesiredDist *= self.desiredFaceWidth\n\t\tscale = desiredDist / dist\n\n\t\t# compute center (x, y)-coordinates (i.e., the median point)\n\t\t# between the two eyes in the input image\n\t\teyesCenter = (int((leftEyeCenter[0] + rightEyeCenter[0]) // 2),\n\t\t\t(int(leftEyeCenter[1] + rightEyeCenter[1]) // 2))\n\n\t\t# grab the rotation matrix for rotating and scaling the face\n\t\tM = cv2.getRotationMatrix2D(eyesCenter, angle, scale)\n\n\t\t# update the translation component of the matrix\n\t\ttX = self.desiredFaceWidth * 0.5\n\t\ttY = self.desiredFaceHeight * self.desiredLeftEye[1]\n\t\tM[0, 2] += (tX - eyesCenter[0])\n\t\tM[1, 2] += (tY - eyesCenter[1])\n\n\t\t# apply the affine transformation\n\t\t(w, h) = (self.desiredFaceWidth, self.desiredFaceHeight)\n\t\toutput = cv2.warpAffine(image, M, (w, h),\n\t\t\tflags=cv2.INTER_CUBIC)\n\n\t\t# return the aligned face\n\t\treturn output","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"detector = dlib.get_frontal_face_detector()\npredictor = dlib.shape_predictor('../input/models/landmarks.dat')\nfa = FaceAligner(predictor, desiredFaceWidth=512)\n\ndef align_images(path):\n    DIR = os.listdir(path)\n    for img in DIR :\n        print(img)\n        image = cv2.imread(path+img)\n        image = imutils.resize(image, width=800)\n        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        rects = detector(gray, 2)\n\n# loop over the face detections\n        for rect in rects:\n\t# extract the ROI of the *original* face, then align the face\n\t# using facial landmarks\n            (x, y, w, h) = rect_to_bb(rect)\n            faceOrig = imutils.resize(image[y:y + h, x:x + w], width=512)\n            faceAligned = fa.align(image, gray, rect)\n            cv2.imwrite(\"./aligned-\"+img,faceAligned)\n            print(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATH = \"../input/more-idols/\"\nalign_images(PATH)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}